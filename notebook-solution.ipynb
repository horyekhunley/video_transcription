{"cells":[{"cell_type":"markdown","id":"bbf7941b-6c0a-4b14-b1fc-c703e57e352b","metadata":{},"source":["# Building Multimodal AI Applications with LangChain & the OpenAI API "]},{"cell_type":"markdown","id":"3e302e1c-4c18-4c44-87fd-ba935c3a0853","metadata":{},"source":["- Understanding the building blocks of working with Multimodal AI projects\n","- Working with some of the fundamental concepts of LangChain  \n","- How to use the Whisper API to transcribe audio to text \n","- How to combine both LangChain and Whisper API to create ask questions of any YouTube video "]},{"cell_type":"markdown","id":"823598ac-fa77-4532-997d-2923d0017e90","metadata":{},"source":["The project requires several packages that need to be installed into Workspace.\n","\n","- `langchain` is a framework for developing generative AI applications.\n","- `yt_dlp` lets you download YouTube videos.\n","- `tiktoken` converts text into tokens.\n","- `docarray` makes it easier to work with multi-model data (in this case mixing audio and text)."]},{"cell_type":"code","execution_count":1,"id":"541cd9f5-0aaa-4374-8411-25bedecd8c84","metadata":{"executionCancelledAt":null,"executionTime":2566,"lastExecutedAt":1695381616329,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Importing the Required Packages including: \"os\" \"openai\" \"yt_dlp as youtube_dl\" and \"from yt_dl import Download Error\"\n\n# Import the os package\nimport os  \n\n# Import the glob package\nimport glob\n\n# Import the openai package \nimport openai \n\n# Import the yt_dlp package as youtube_dl\nimport yt_dlp as youtube_dl \n\n# Import DownloadError from yt_dlp\nfrom yt_dlp import DownloadError \n\nimport docarray ","outputsMetadata":{"0":{"height":77,"type":"stream"}}},"outputs":[],"source":["import os \n","import glob\n","import openai \n","import yt_dlp as youtube_dl\n","from yt_dlp import DownloadError \n","import docarray "]},{"cell_type":"markdown","id":"794e2ce2-ba13-446f-9ac7-2b5743f65a51","metadata":{},"source":["We will also assign the variable `openai_api_key` to the environment variable \"OPEN_AI_KEY\". This will help keep our key secure and remove the need to write it in the code here. "]},{"cell_type":"code","execution_count":2,"id":"7156b205-f844-4d9e-8867-449ff5840839","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1695381359221,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"openai_api_key = os.getenv(\"OPENAI_API_KEY\")"},"outputs":[],"source":["openai_api_key = os.getenv(\"OPENAI_API_KEY\")"]},{"cell_type":"markdown","id":"48abc459-48e5-4c7c-a795-daaf347ceef6","metadata":{},"source":["After creating the setup, the first step we will need to do is download the video from Youtube and convert it to an audio file (.mp3). \n","\n","We'll download a DataCamp tutorial about machine learning in Python.\n","\n","We will do this by setting a variable to store the `youtube_url` and the `output_dir` that we want the file to be stored. \n","\n","The `yt_dlp` allows us to download and convert in a few steps but does require a few configuration steps. This code is provided to you. \n","\n","Lastly, we will create a loop that looks in the `output_dir` to find any .mp3 files. Then we will store those in a list called `audio_files` that will be used later to send each file to the Whisper model for transcription. "]},{"cell_type":"code","execution_count":10,"id":"ffb3836d-7b1b-47db-9ccc-6910972dd045","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":13030,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1695381382849,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# An example YouTube tutorial video\nyoutube_url = \"https://www.youtube.com/watch?v=aqzxYofJ_ck\"\n# Directory to store the downloaded video\noutput_dir = \"files/audio/\"\n\n# Config for youtube-dl\nydl_config = {\n    \"format\": \"bestaudio/best\",\n    \"postprocessors\": [\n        {\n            \"key\": \"FFmpegExtractAudio\",\n            \"preferredcodec\": \"mp3\",\n            \"preferredquality\": \"192\",\n        }\n    ],\n    \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n    \"verbose\": True\n}\n\n# Check if the output directory exists, if not create it\n\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# Print a message indicating which video is being downloaded\n\nprint(f\"Downloading video from {youtube_url}\")\n\n\n# Attempt to download the video using the specified configuration\n# If a DownloadError occurs, attempt to download the video again\n\ntry:\n    with youtube_dl.YoutubeDL(ydl_config) as ydl:\n        ydl.download([youtube_url])\nexcept DownloadError:\n    with youtube_dl.YoutubeDL(ydl_config) as ydl:\n        ydl.download([youtube_url])\n\n\n","outputsMetadata":{"0":{"height":357,"type":"stream"},"1":{"height":137,"type":"stream"},"2":{"height":97,"type":"stream"},"3":{"height":37,"type":"stream"},"4":{"height":257,"type":"stream"},"5":{"height":77,"type":"stream"},"6":{"height":57,"type":"stream"},"7":{"height":57,"type":"stream"},"8":{"height":97,"type":"stream"},"9":{"height":77,"type":"stream"}}},"outputs":[{"name":"stderr","output_type":"stream","text":["[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n","[debug] yt-dlp version stable@2023.07.06 [b532a3481] (pip) API\n","[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': 'files/audio/%(title)s.%(ext)s', 'verbose': True, 'compat_opts': set()}\n","[debug] Python 3.12.1 (CPython x86_64 64bit) - Linux-6.7.0-204.fsync.fc39.x86_64-x86_64-with-glibc2.38 (OpenSSL 3.2.1 30 Jan 2024, glibc 2.38)\n","[debug] exe versions: ffmpeg 6.0.1 (fdk,setts), ffprobe 6.0.1\n","[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2023.11.17, mutagen-1.47.0, sqlite3-2.6.0, websockets-12.0\n","[debug] Proxy map: {}\n","[debug] Loaded 1855 extractors\n"]},{"name":"stdout","output_type":"stream","text":["Downloading video from https://www.youtube.com/watch?v=jGn95KDWZMU&list=WL&index=13\n","[youtube:tab] Extracting URL: https://www.youtube.com/watch?v=jGn95KDWZMU&list=WL&index=13\n","[youtube:tab] Downloading playlist WL - add --no-playlist to download just the video jGn95KDWZMU\n","[youtube:tab] WL: Downloading webpage\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: [youtube:tab] Unable to recognize playlist. Downloading just video jGn95KDWZMU\n"]},{"name":"stdout","output_type":"stream","text":["[youtube] Extracting URL: https://www.youtube.com/watch?v=jGn95KDWZMU\n","[youtube] jGn95KDWZMU: Downloading webpage\n","[youtube] jGn95KDWZMU: Downloading ios player API JSON\n","[youtube] jGn95KDWZMU: Downloading android player API JSON\n","[youtube] jGn95KDWZMU: Downloading player a1d7d0f8\n"]},{"name":"stderr","output_type":"stream","text":["[debug] Saving youtube-nsig.a1d7d0f8 to cache\n","[debug] [youtube] Decrypted nsig 1J19f-KCYbVpaBQ5G => m6EB7vAtsB5fAg\n"]},{"name":"stdout","output_type":"stream","text":["[youtube] jGn95KDWZMU: Downloading m3u8 information\n"]},{"name":"stderr","output_type":"stream","text":["[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n","[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"]},{"name":"stdout","output_type":"stream","text":["[info] jGn95KDWZMU: Downloading 1 format(s): 251\n"]},{"name":"stderr","output_type":"stream","text":["[debug] Invoking http downloader on \"https://rr1---sn-cu-cime7.googlevideo.com/videoplayback?expire=1706996134&ei=Rl2-ZemiDYughcIP0ve4qAE&ip=95.149.40.138&id=o-AEkIywv3dR5VSbATNqlr1FMPrPOVGg2wqaxDGQjQWkZy&itag=251&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=_s&mm=31%2C29&mn=sn-cu-cime7%2Csn-cu-c9i6&ms=au%2Crdu&mv=m&mvi=1&pl=25&initcwndbps=1687500&vprv=1&svpuc=1&mime=audio%2Fwebm&gir=yes&clen=7581236&dur=477.941&lmt=1705032951893615&mt=1706973920&fvip=5&keepalive=yes&fexp=24007246&c=ANDROID&txp=5318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRgIhANuTSy8UUDNl_ZoXAWJs1s-copsAoVy-9lbVF5mjtGkbAiEA5U_rf66WfG8wnnNtQJrSoFAwj5Hi4wrHLx88EB6JJ54%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Cinitcwndbps&lsig=AAO5W4owRgIhAONbxHSDrIqL5xJ8edPpFPEVDzAd6JJbKXQsGV_qeGSNAiEAoe1QL6puiE9NDZ4bk7xxlHWaemo7Ssw-WKawcJ3G-qA%3D\"\n"]},{"name":"stdout","output_type":"stream","text":["[download] Destination: files/audio/5 Questions Every Data Scientist Should Hardcode into Their Brain.webm\n","[download] 100% of    7.23MiB in 00:00:00 at 7.25MiB/s   \n"]},{"name":"stderr","output_type":"stream","text":["[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/5 Questions Every Data Scientist Should Hardcode into Their Brain.webm'\n"]},{"name":"stdout","output_type":"stream","text":["[ExtractAudio] Destination: files/audio/5 Questions Every Data Scientist Should Hardcode into Their Brain.mp3\n"]},{"name":"stderr","output_type":"stream","text":["[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/5 Questions Every Data Scientist Should Hardcode into Their Brain.webm' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/5 Questions Every Data Scientist Should Hardcode into Their Brain.mp3'\n"]},{"name":"stdout","output_type":"stream","text":["Deleting original file files/audio/5 Questions Every Data Scientist Should Hardcode into Their Brain.webm (pass -k to keep)\n"]}],"source":["# An example YouTube tutorial video\n","youtube_url = \"https://www.youtube.com/watch?v=jGn95KDWZMU&list=WL&index=13\"\n","# Directory to store the downloaded video\n","output_dir = \"files/audio/\"\n","\n","# Config for youtube-dl\n","ydl_config = {\n","    \"format\": \"bestaudio/best\",\n","    \"postprocessors\": [\n","        {\n","            \"key\": \"FFmpegExtractAudio\",\n","            \"preferredcodec\": \"mp3\",\n","            \"preferredquality\": \"192\",\n","        }\n","    ],\n","    \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n","    \"verbose\": True\n","}\n","\n","# Check if the output directory exists, if not create it\n","if not os.path.exists(output_dir): \n","    os.makedirs(output_dir)\n","\n","\n","# Print a message indicating which video is being downloaded\n","\n","print(f\"Downloading video from {youtube_url}\")\n","\n","\n","# Attempt to download the video using the specified configuration\n","# If a DownloadError occurs, attempt to download the video again\n","\n","try: \n","    with youtube_dl.YoutubeDL(ydl_config) as ydl: \n","        ydl.download([youtube_url])\n","except DownloadError: \n","    with youtube_dl.YoutubeDL(ydl_config) as ydl: \n","        ydl.download([youtube_url])"]},{"cell_type":"markdown","id":"df9c586d-309a-411b-90a5-6e81fe85eda4","metadata":{},"source":["To find the audio files that we will use the `glob`module that looks in the `output_dir` to find any .mp3 files. Then we will append the file to a list called `audio_files`. This will be used later to send each file to the Whisper model for transcription. "]},{"cell_type":"code","execution_count":11,"id":"c3d0a34d-ade9-4314-bc7d-480f165b3992","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1695381382903,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Find the audio file in the output directory\n\n# Find all the audio files in the output directory\naudio_files = glob.glob(os.path.join(output_dir, \"*.mp3\"))\n\n# Select the first audio file in the list\naudio_filename = audio_files[0]\n\n# Print the name of the selected audio file\nprint(audio_filename)","outputsMetadata":{"0":{"height":56,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["files/audio/5 Questions Every Data Scientist Should Hardcode into Their Brain.mp3\n"]}],"source":["# Find all the audio files in the output directory\n","audio_files = glob.glob(os.path.join(output_dir, \"*.mp3\"))\n","\n","# Select the first audio file in the list\n","audio_filename = audio_files[0]\n","\n","# Print the name of the selected audio file\n","print(audio_filename)"]},{"cell_type":"code","execution_count":12,"id":"54306dcc-40f7-4a12-97ef-388b95c70ad4","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":1667,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1695385362796,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define function parameters\naudio_file = audio_filename\noutput_file = \"files/transcripts/transcript.txt\"\nmodel = \"whisper-1\"\n\n# Print the name of the audio file\nprint(audio_file)\n\n# Transcribe the audio file to text using OpenAI API\nprint(\"converting audio to text...\")\nwith open(audio_file, \"rb\") as audio:\n    response = openai.Audio.transcribe(model, audio)\n\n# Extract the transcript from the response\ntranscript = (response[\"text\"])\n","outputsMetadata":{"0":{"height":76,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["files/audio/5 Questions Every Data Scientist Should Hardcode into Their Brain.mp3\n","converting audio to text...\n"]}],"source":["# Define function parameters\n","audio_file = audio_filename\n","output_file = \"files/transcripts/transcript.txt\"\n","model = \"whisper-1\"\n","\n","# Print the name of the audio file\n","print(audio_file)\n","\n","# Transcribe the audio file to text using OpenAI API\n","print(\"converting audio to text...\")\n","\n","with open(audio_file, \"rb\") as audio:\n","    response = openai.Audio.transcribe(model, audio)\n","\n","# Extract the transcript from the response\n","transcript = (response[\"text\"])"]},{"cell_type":"markdown","id":"7255d301-69e2-4e04-813d-5a90b5ebcbdc","metadata":{},"source":["To save the transcripts to text files we will use the below provided code: "]},{"cell_type":"code","execution_count":13,"id":"6798bff4-ac8d-46e3-8c62-e540655e859d","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":28,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1695381457561,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# If an output file is specified, save the transcript to a .txt file\n\nif output_file is not None:\n    # Create the directory for the output file if it doesn't exist\n    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n    # Write the transcript to the output file\n    with open(output_file, \"w\") as file:\n        file.write(transcript)\n\n# Print the transcript to the console to verify it worked \nprint(transcript)\n\n","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Data science is more than just building fancy machine learning models. When you boil it down, the key objective of data science is to solve problems. The trouble, however, is at the outset of most data science projects, we rarely have a well-defined problem. In these situations, the role of a data scientist isn't to have all the answers, but rather to ask the right questions. In this video, I'll share five questions that every data scientist should hard-code into their brain to make identifying and defining business problems second nature. And if you're new here, I'm Shah. I make content about data science and entrepreneurship. And if you enjoyed this video, please consider subscribing. That's a great no-cost way to support me in all the content that I make. Before diving into the questions, I wanna give some context for where they are coming from. Like many others, when I started my data science journey, I was hyper-focused on learning tools and technologies. While this technical foundation is necessary to be a successful data scientist, focusing too much on tools creates the hammer problem, which is when you have a really nice hammer, everything looks like a nail. This often leads to projects that are intellectually stimulating, yet practically useless. I finally outgrew this approach when I joined a data science team at a large enterprise. The key lesson from that experience was the importance of focusing on problems rather than technologies. This means that one should gain a sufficiently deep understanding of the business problem before writing a single line of code. And since as data scientists, we don't typically solve our own problems, we gain this understanding through conversations with stakeholders and clients. Getting this right is important because if you don't, you can spend a lot of time and money solving the wrong problem. This is where problem discovery questions come in. Over the past six months, I've developed a bit of an obsession with cracking these early stage discovery conversations with stakeholders and clients. My approach to getting better at this has been twofold. First, I interviewed 10 seasoned data freelancers about their best practices and how they approach these conversations. And second, I took as many discovery calls as possible, which ended up being around 25. The five questions I share here are the culmination of all these efforts. While this is by no means a complete list, these are questions that seem to come up over and over again. So the first question here is, what problem are you trying to solve? While in theory, this should be the only question you need to ask, in practice, things don't typically work out that way. In most instances, clients aren't super clear on the problem that they need to solve. And even if they are, I typically will need to do some catching up to better understand the business context. Either way, this question is helpful because it ideally brings up follow-up questions, which allow me to dig deeper into the client's world. For example, if a client says, we tried creating a custom chatbot with OpenAI, but it didn't provide good results. I might ask, what was the chatbot used for? Or what makes you say the results weren't good? And a lot of times, if a follow-up question doesn't come to mind, I find a really helpful practice is just to rephrase and summarize what the client tells me. Most times, this is another way to keep the conversation going and keep digging into the challenges that the client is facing. A natural way to follow up the what question is why. This is one of the most powerful questions you can ask a client because it can unlock the floodgates to the client's motivations, goals, assumptions, and beyond. However, why questions have a tendency to make people defensive, which is why having multiple ways of phrasing this question can be helpful. Some examples of this are as follows. Why is this important to your business? Why do you wanna solve this now? What does solving this mean for your business? How does this fit into the larger goals of your business? Why do you wanna use AI to solve this problem? The key benefit of asking the why question or any of its variants is that they allow you to dig more deeply into the client's problem and ultimately identify the root cause. This is reminiscent of Toyota's five whys approach, which teaches to get to the root cause of any problem, one should ask why five times. These first two questions of what are we doing and why are we doing it are two of the most fundamental questions in business. So getting really good at asking what and why in many different ways can take you very far. The next question is, what's your dream outcome? I like this question because it essentially combines the what and why questions. And it tends to get people to speak to their vision of the project in a way that may not come through when asked directly. Having multiple ways of asking what and why is important because it often takes a few passes to really get to the root cause of a client's problem. Two related questions here are, what does success look like and how would we measure it? These are a bit more pragmatic than a dream outcome, but are helpful for transitioning from asking what and why to how. The next question is, what have you tried so far? This helps narrow down potential solutions in two ways. One, it helps avoid wasting time on things that didn't work. And two, any new project should build upon existing work. This latter point is based on the philosophy that data science projects should seek incremental innovation. Therefore, they should be simple and iterative. For situations where the client hasn't built anything so far, one can ask any of the following questions. What is the existing solution? How do you solve this problem now? What have others done to solve a similar problem? In either case, these questions help set the stage for the project and help you avoid reinventing the wheel. The final question is one I got from master negotiator, Chris Voss, which is, why me? Asking this question is an effective way to reveal people's motivations for talking to you. Often, this sparks additional context of what led them to you and how they see you fitting into the project, which is helpful for next steps. Sometimes, however, people don't have good answers to this question, which may indicate they don't actually wanna work with you and they're holding back some deeper motive, such as they're looking for free consulting or they're looking for a competing bid to take to the person they actually wanna work with. A key lesson for me these past six months was to learn these questions, i.e., hard-code them into my brain, but then forget about them. The point isn't to mindlessly go down a list of questions when talking to clients, but rather get to the point where these questions naturally form in your mind during the flow of conversation. This intuition is something that can only develop through practice. Toward that end, here are three key takeaways that have been helpful to me in developing this skillset. First, don't just study these questions, use them. While this may result in a fair share of awkward moments, it's all part of the learning process. And don't worry, I'm still learning too. Second is to stay curious. The goal of these early-stage conversations isn't to look smart or sell, but rather to learn, which brings up the final takeaway. Listen more than you talk. My rule of thumb is to wait until the last five to 10 minutes of a 30-minute call to start offering recommendations and next steps. Prior to that, my challenge is to ask questions, rephrase and summarize client answers, and to ask follow-up questions following my natural curiosity. If you enjoyed this content, please consider subscribing. That's a great no-cost way you can support me in all the videos that I make. To read more about this topic, check out the blog in Towards Data Science, which you can access using the friend link in the description below. Like I said earlier, this is by no means a complete list, so if you have anything to add, please drop those in the comments section below. And as always, thank you so much for your time, and thanks for watching.\n"]}],"source":["# If an output file is specified, save the transcript to a .txt file\n","\n","if output_file is not None:\n","    # Create the directory for the output file if it doesn't exist\n","    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n","    # Write the transcript to the output file\n","    with open(output_file, \"w\") as file:\n","        file.write(transcript)\n","\n","# Print the transcript to the console to verify it worked \n","print(transcript)"]},{"cell_type":"code","execution_count":18,"id":"bb8654f7-965e-4e62-98ab-d08b7026e3d9","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1695381464265,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the TextLoader class from the langchain.document_loaders module\n\nfrom langchain.document_loaders import TextLoader\n\n# Create a new instance of the TextLoader class, specifying the directory containing the text files\n\nloader = TextLoader(\"./files/text\")\n\n# Load the documents from the specified directory using the TextLoader instance\n\ndocs = loader.load()"},"outputs":[],"source":["# Import the TextLoader class from the langchain.document_loaders module\n","from langchain.document_loaders import TextLoader\n","\n","# Create a new instance of the TextLoader class, specifying the directory containing the text files\n","loader = TextLoader(\"./files/transcripts/transcript.txt\")\n","\n","# Load the documents from the specified directory using the TextLoader instance\n","docs = loader.load()"]},{"cell_type":"code","execution_count":19,"id":"269aaed5-7d07-43d7-a2d0-a89730ec4bc9","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":18,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1695381467004,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Show the first element of docs to verify it has been loaded \ndocs[0]"},"outputs":[{"data":{"text/plain":["Document(page_content=\"Data science is more than just building fancy machine learning models. When you boil it down, the key objective of data science is to solve problems. The trouble, however, is at the outset of most data science projects, we rarely have a well-defined problem. In these situations, the role of a data scientist isn't to have all the answers, but rather to ask the right questions. In this video, I'll share five questions that every data scientist should hard-code into their brain to make identifying and defining business problems second nature. And if you're new here, I'm Shah. I make content about data science and entrepreneurship. And if you enjoyed this video, please consider subscribing. That's a great no-cost way to support me in all the content that I make. Before diving into the questions, I wanna give some context for where they are coming from. Like many others, when I started my data science journey, I was hyper-focused on learning tools and technologies. While this technical foundation is necessary to be a successful data scientist, focusing too much on tools creates the hammer problem, which is when you have a really nice hammer, everything looks like a nail. This often leads to projects that are intellectually stimulating, yet practically useless. I finally outgrew this approach when I joined a data science team at a large enterprise. The key lesson from that experience was the importance of focusing on problems rather than technologies. This means that one should gain a sufficiently deep understanding of the business problem before writing a single line of code. And since as data scientists, we don't typically solve our own problems, we gain this understanding through conversations with stakeholders and clients. Getting this right is important because if you don't, you can spend a lot of time and money solving the wrong problem. This is where problem discovery questions come in. Over the past six months, I've developed a bit of an obsession with cracking these early stage discovery conversations with stakeholders and clients. My approach to getting better at this has been twofold. First, I interviewed 10 seasoned data freelancers about their best practices and how they approach these conversations. And second, I took as many discovery calls as possible, which ended up being around 25. The five questions I share here are the culmination of all these efforts. While this is by no means a complete list, these are questions that seem to come up over and over again. So the first question here is, what problem are you trying to solve? While in theory, this should be the only question you need to ask, in practice, things don't typically work out that way. In most instances, clients aren't super clear on the problem that they need to solve. And even if they are, I typically will need to do some catching up to better understand the business context. Either way, this question is helpful because it ideally brings up follow-up questions, which allow me to dig deeper into the client's world. For example, if a client says, we tried creating a custom chatbot with OpenAI, but it didn't provide good results. I might ask, what was the chatbot used for? Or what makes you say the results weren't good? And a lot of times, if a follow-up question doesn't come to mind, I find a really helpful practice is just to rephrase and summarize what the client tells me. Most times, this is another way to keep the conversation going and keep digging into the challenges that the client is facing. A natural way to follow up the what question is why. This is one of the most powerful questions you can ask a client because it can unlock the floodgates to the client's motivations, goals, assumptions, and beyond. However, why questions have a tendency to make people defensive, which is why having multiple ways of phrasing this question can be helpful. Some examples of this are as follows. Why is this important to your business? Why do you wanna solve this now? What does solving this mean for your business? How does this fit into the larger goals of your business? Why do you wanna use AI to solve this problem? The key benefit of asking the why question or any of its variants is that they allow you to dig more deeply into the client's problem and ultimately identify the root cause. This is reminiscent of Toyota's five whys approach, which teaches to get to the root cause of any problem, one should ask why five times. These first two questions of what are we doing and why are we doing it are two of the most fundamental questions in business. So getting really good at asking what and why in many different ways can take you very far. The next question is, what's your dream outcome? I like this question because it essentially combines the what and why questions. And it tends to get people to speak to their vision of the project in a way that may not come through when asked directly. Having multiple ways of asking what and why is important because it often takes a few passes to really get to the root cause of a client's problem. Two related questions here are, what does success look like and how would we measure it? These are a bit more pragmatic than a dream outcome, but are helpful for transitioning from asking what and why to how. The next question is, what have you tried so far? This helps narrow down potential solutions in two ways. One, it helps avoid wasting time on things that didn't work. And two, any new project should build upon existing work. This latter point is based on the philosophy that data science projects should seek incremental innovation. Therefore, they should be simple and iterative. For situations where the client hasn't built anything so far, one can ask any of the following questions. What is the existing solution? How do you solve this problem now? What have others done to solve a similar problem? In either case, these questions help set the stage for the project and help you avoid reinventing the wheel. The final question is one I got from master negotiator, Chris Voss, which is, why me? Asking this question is an effective way to reveal people's motivations for talking to you. Often, this sparks additional context of what led them to you and how they see you fitting into the project, which is helpful for next steps. Sometimes, however, people don't have good answers to this question, which may indicate they don't actually wanna work with you and they're holding back some deeper motive, such as they're looking for free consulting or they're looking for a competing bid to take to the person they actually wanna work with. A key lesson for me these past six months was to learn these questions, i.e., hard-code them into my brain, but then forget about them. The point isn't to mindlessly go down a list of questions when talking to clients, but rather get to the point where these questions naturally form in your mind during the flow of conversation. This intuition is something that can only develop through practice. Toward that end, here are three key takeaways that have been helpful to me in developing this skillset. First, don't just study these questions, use them. While this may result in a fair share of awkward moments, it's all part of the learning process. And don't worry, I'm still learning too. Second is to stay curious. The goal of these early-stage conversations isn't to look smart or sell, but rather to learn, which brings up the final takeaway. Listen more than you talk. My rule of thumb is to wait until the last five to 10 minutes of a 30-minute call to start offering recommendations and next steps. Prior to that, my challenge is to ask questions, rephrase and summarize client answers, and to ask follow-up questions following my natural curiosity. If you enjoyed this content, please consider subscribing. That's a great no-cost way you can support me in all the videos that I make. To read more about this topic, check out the blog in Towards Data Science, which you can access using the friend link in the description below. Like I said earlier, this is by no means a complete list, so if you have anything to add, please drop those in the comments section below. And as always, thank you so much for your time, and thanks for watching.\", metadata={'source': './files/transcripts/transcript.txt'})"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Show the first element of docs to verify it has been loaded \n","docs[0]"]},{"cell_type":"markdown","id":"79af9e43-c32f-478d-b057-dc3b7890925e","metadata":{},"source":["Now that we have created Documents of the transcription, we will store that Document in a vector store. Vector stores allows LLMs to traverse through data to find similiarity between different data based on their distance in space. \n","\n","For large amounts of data, it is best to use a designated Vector Database. Since we are only using one transcript for this tutorial, we can create an in-memory vector store using the `docarray` package. \n","\n","We will also tokenize our queries using the `tiktoken` package. This means that our query will be seperated into smaller parts either by phrases, words or characters. Each of these parts are assigned a token which helps the model \"understand\" the text and relationships with other tokens. "]},{"cell_type":"code","execution_count":20,"id":"15298bd3-5465-450d-b917-5e5d87d78bf2","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1695381479098,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the tiktoken package\nimport tiktoken"},"outputs":[],"source":["# Import the tiktoken package\n","import tiktoken"]},{"cell_type":"markdown","id":"22438b44-b8f8-4c78-a573-87ee4bdb2234","metadata":{},"source":["We will now use LangChain to complete some important operations to create the Question and Answer experience. Let's import the following: \n","\n","- Import `RetrievalQA` from `langchain.chains` - this chain first retrieves documents from an assigned Retriver and then runs a QA chain for answering over those documents \n","- Import `ChatOpenAI` from `langchain.chat_models` - this imports the ChatOpenAI model that we will use to query the data \n","- Import `DocArrayInMemorySearch` from `langchain.vectorstores` - this gives the ability to search over the vector store we have created. \n","- Import `OpenAIEmbeddings` from `langchain.embeddings` - this will create embeddings for the data store in the vector store. \n","- Import `display` and `Markdown`from `IPython.display` - this will create formatted responses to the queries. ("]},{"cell_type":"code","execution_count":21,"id":"3a7fb40d-de20-4ec8-b05a-036b6dc6ad66","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1695381482721,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the RetrievalQA class from the langchain.chains module\nfrom langchain.chains import RetrievalQA\n\n# Import the ChatOpenAI class from the langchain.chat_models module\nfrom langchain.chat_models import ChatOpenAI\n\n# Import the DocArrayInMemorySearch class from the langchain.vectorstores module\nfrom langchain.vectorstores import DocArrayInMemorySearch\n\n# Import the OpenAIEmbeddings class from the langchain.embeddings module\nfrom langchain.embeddings import OpenAIEmbeddings"},"outputs":[],"source":["# Import the RetrievalQA class from the langchain.chains module\n","from langchain.chains import RetrievalQA\n","\n","# Import the ChatOpenAI class from the langchain.chat_models module\n","from langchain.chat_models import ChatOpenAI\n","\n","# Import the DocArrayInMemorySearch class from the langchain.vectorstores module\n","from langchain.vectorstores import DocArrayInMemorySearch\n","\n","# Import the OpenAIEmbeddings class from the langchain.embeddings module\n","from langchain.embeddings import OpenAIEmbeddings"]},{"cell_type":"markdown","id":"9bec39d2-8a4c-4638-953f-fbd9fa47ad6f","metadata":{},"source":["Now we will create a vector store that will use the `DocArrayInMemory` search methods which will search through the created embeddings created by the OpenAI Embeddings function. "]},{"cell_type":"code","execution_count":22,"id":"66ef212c-eefd-4cf2-a02c-3c01b1b29118","metadata":{"executionCancelledAt":null,"executionTime":1041,"lastExecutedAt":1695381624056,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a new DocArrayInMemorySearch instance from the specified documents and embeddings\ndb = DocArrayInMemorySearch.from_documents(\n    docs, \n    OpenAIEmbeddings()\n)"},"outputs":[],"source":["# Create a new DocArrayInMemorySearch instance from the specified documents and embeddings\n","db = DocArrayInMemorySearch.from_documents(\n","    docs, \n","    OpenAIEmbeddings()\n",")"]},{"cell_type":"code","execution_count":23,"id":"7c7f6113-c145-47ff-ab9c-ada04ca047ce","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1695381626978,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Convert the DocArrayInMemorySearch instance to a retriever\nretriever = db.as_retriever()\n\n# Create a new ChatOpenAI instance with a temperature of 0.0\nllm = ChatOpenAI(temperature = 0.0)"},"outputs":[],"source":["# Convert the DocArrayInMemorySearch instance to a retriever\n","retriever = db.as_retriever()\n","\n","# Create a new ChatOpenAI instance with a temperature of 0.0\n","llm = ChatOpenAI(temperature = 0.0)"]},{"cell_type":"code","execution_count":24,"id":"09fc202b-198f-4510-8d81-258f914d5c08","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1695381629777,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a new RetrievalQA instance with the specified parameters\nqa_stuff = RetrievalQA.from_chain_type(\n    llm=llm,            # The ChatOpenAI instance to use for generating responses\n    chain_type=\"stuff\", # The type of chain to use for the QA system\n    retriever=retriever, # The retriever to use for retrieving relevant documents\n    verbose=True        # Whether to print verbose output during retrieval and generation\n)"},"outputs":[],"source":["# Create a new RetrievalQA instance with the specified parameters\n","qa_stuff = RetrievalQA.from_chain_type(\n","    llm=llm,            # The ChatOpenAI instance to use for generating responses\n","    chain_type=\"stuff\", # The type of chain to use for the QA system\n","    retriever=retriever, # The retriever to use for retrieving relevant documents\n","    verbose=True        # Whether to print verbose output during retrieval and generation\n",")"]},{"cell_type":"markdown","id":"d51218d4-4e81-4d87-9f3f-77eacde057c1","metadata":{},"source":["Now we are ready to create queries about the YouTube video and read the responses from the LLM. This done first by creating a query and then running the RetrievalQA we setup in the last step and passing it the query. "]},{"cell_type":"code","execution_count":25,"id":"d576672c-5078-487a-9dc5-3703f17d82f1","metadata":{"executionCancelledAt":null,"executionTime":4949,"lastExecutedAt":1695381641995,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Set the query to be used for the QA system\nquery = \"What is this tutorial about?\"\n\n# Run the query through the RetrievalQA instance and store the response\nresponse = qa_stuff.run(query)\n\n# Print the response to the console\nresponse\n","outputsMetadata":{"0":{"height":76,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["\"This video is about the importance of asking the right questions in data science projects. The speaker shares five key questions that every data scientist should ask to identify and define business problems effectively. These questions help in understanding the client's needs, motivations, and desired outcomes, ultimately leading to successful data science projects.\""]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# Set the query to be used for the QA system\n","query = \"What is this video about?\"\n","\n","# Run the query through the RetrievalQA instance and store the response\n","response = qa_stuff.run(query)\n","\n","# Print the response to the console\n","response\n"]},{"cell_type":"markdown","id":"de9f2df3-87d1-40d3-862a-95769c11d015","metadata":{},"source":["We can continue on creating queries and even creating queries that we know would not be answered in this video to see how the model responds. "]},{"cell_type":"code","execution_count":26,"id":"dbb75225-76c1-4eb8-9055-e13a3bb68682","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":117,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["'The video does not provide information about the difference between a training set and a test set.'"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# Set the query to be used for the QA system\n","query = \"What is the difference between a training set and test set?\"\n","\n","# Run the query through the RetrievalQA instance and store the response\n","response = qa_stuff.run(query)\n","\n","# Print the response to the console\n","response"]},{"cell_type":"code","execution_count":27,"id":"13864a14-0eda-4afd-bfe5-90fdefbc5d49","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":117,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["'This lesson is primarily targeted towards data scientists or individuals interested in data science. It provides valuable insights and questions that can help data scientists in identifying and defining business problems.'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Set the query to be used for the QA system\n","query = \"Who should watch this lesson?\"\n","\n","# Run the query through the RetrievalQA instance and store the response\n","response = qa_stuff.run(query)\n","\n","# Print the response to the console\n","response "]},{"cell_type":"code","execution_count":28,"id":"c62b73e4-e746-49f9-8106-921cbb4e6df8","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":117,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["\"I don't know the answer to that question as it is subjective and can vary depending on personal opinions and criteria for determining greatness.\""]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Set the query to be used for the QA system\n","query =\"Who is the greatest football team on earth?\"\n","\n","# Run the query through the RetrievalQA instance and store the response\n","response = qa_stuff.run(query)\n","\n","# Print the response to the console\n","response "]},{"cell_type":"code","execution_count":30,"id":"f9f7a7f3-f0f1-44ad-be76-d15aa009ac34","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":117,"type":"stream"},"1":{"height":77,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","The main points in this video are:\n","\n","1. The key objective of data science is to solve problems, and data scientists should focus on asking the right questions.\n","2. It is important to gain a deep understanding of the business problem before writing any code.\n","3. The video presents five important questions that every data scientist should ask during problem discovery conversations with stakeholders and clients.\n","4. The questions include: What problem are you trying to solve? Why is this important to your business? What's your dream outcome? What have you tried so far? Why me?\n","5. The video emphasizes the importance of practicing and developing the intuition to naturally ask these questions during conversations.\n","6. The video concludes with the importance of listening more than talking and waiting until the end of the conversation to offer recommendations and next steps.\n"]}],"source":["# Set the query to be used for the QA system\n","query = \"What are the main points in this video?\"\n","\n","# Run the query through the RetrievalQA instance and store the response\n","response = qa_stuff.run(query)\n","\n","# Print the response to the console\n","print(response) "]},{"cell_type":"code","execution_count":null,"id":"93f11cf3","metadata":{},"outputs":[],"source":[]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":5}
